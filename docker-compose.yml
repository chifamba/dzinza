# Dzinza Genealogy Platform - Docker Compose Configuration
# Complete development and production environment setup

# Define global secrets - in a real setup, these would point to files or be managed by an orchestrator
secrets:
  db_password:
    file: ./secrets/db_password.txt
  mongo_password:
    file: ./secrets/mongo_password.txt
  redis_password:
    file: ./secrets/redis_password.txt
  elasticsearch_password:
    file: ./secrets/elasticsearch_password.txt # If used
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  jwt_refresh_secret:
    file: ./secrets/jwt_refresh_secret.txt
  api_key_general: # Renamed to avoid conflict if other API keys are service specific
    file: ./secrets/api_key_general.txt
  aws_access_key_id:
    file: ./secrets/aws_access_key_id.txt
  aws_secret_access_key:
    file: ./secrets/aws_secret_access_key.txt
  smtp_pass:
    file: ./secrets/smtp_pass.txt
  grafana_password:
    file: ./secrets/grafana_password.txt
  google_client_id:
    file: ./secrets/google_client_id.txt
  google_client_secret:
    file: ./secrets/google_client_secret.txt
  minio_access_key:
    file: ./secrets/minio_access_key.txt
  minio_secret_key:
    file: ./secrets/minio_secret_key.txt
  # Add other external API key secrets here as needed
  # Example:
  # openai_api_key:
  #   file: ./secrets/openai_api_key.txt
  seed_admin_password:
    file: ./secrets/seed_admin_password.txt

services:
  # Base image for Python services (not a runnable service itself, but context for builds)
  # This entry is more for reference; actual services will use this context.
  # python_base:
  #   build:
  #     context: ./base
  #     dockerfile: Dockerfile
  #   image: dzinza-python-base:latest # Optional: tag the base image

  # Frontend - React Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: dzinza-frontend
    ports:
      - "8080:8080"
    depends_on:
      - backend_service
    environment:
      - NODE_ENV=production
      - REACT_APP_ENVIRONMENT=production
      - VITE_API_BASE_URL="" # Use relative URLs with nginx proxy
    networks:
      - dzinza-network
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`dzinza.local`)"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Database
  postgres:
    image: postgres:17.5-alpine
    container_name: postgres
    ports:
      - "${DB_PORT:-5432}:5432"
    environment:
      - POSTGRES_DB=${DB_NAME:-dzinza_db}
      - POSTGRES_USER=${DB_USER:-dzinza_user}
      - POSTGRES_PASSWORD_FILE=/run/secrets/db_password # Use secret file
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    secrets: # Grant access to the secret
      - db_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    networks:
      - dzinza-network
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${DB_USER:-dzinza_user} -d ${DB_NAME:-dzinza_db}",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

  # MongoDB for Genealogy Data
  mongodb:
    image: mongo:8.0-noble
    container_name: mongodb
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${DB_USER:-dzinza_user}
      - MONGO_INITDB_ROOT_PASSWORD_FILE=/run/secrets/mongo_password # Use secret file
      - MONGO_INITDB_DATABASE=${MONGODB_GENEALOGY_DB:-dzinza_genealogy}
    secrets: # Grant access to the secret
      - mongo_password
    volumes:
      - mongodb_data:/data/db
      - ./database/mongo-init:/docker-entrypoint-initdb.d
    networks:
      - dzinza-network
    restart: unless-stopped
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache & Session Store
  redis:
    image: redis:8.0.2-alpine
    container_name: redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: ["redis-server", "--requirepass", "redis_secure_password_789"]
    secrets: # Grant access to the secret
      - redis_password
    # Environment variable for REDIS_PASSWORD is no longer needed if accessed via file by the application
    # If the application itself needs REDIS_PASSWORD env var, it should read it from /run/secrets/redis_password
    networks:
      - dzinza-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearch for Search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "bootstrap.memory_lock=true"
      - "cluster.name=dzinza-elasticsearch"
      - "http.cors.enabled=true"
      - 'http.cors.allow-origin="*"'
      - "indices.recovery.max_bytes_per_sec=100mb"
      - "action.destructive_requires_name=false"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - dzinza-network
    restart: unless-stopped
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:v3.4.1
    container_name: prometheus
    ports:
      - "${METRICS_PORT:-9090}:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
    networks:
      - dzinza-network
    restart: unless-stopped

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    ports:
      - "3300:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_password # Use secret file
    secrets: # Grant access to the secret
      - grafana_password
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - dzinza-network
    restart: unless-stopped

  # Python Services (Placeholders - to be implemented)
  auth_service:
    build:
      context: ./auth-service
      dockerfile: Dockerfile # Use service-specific Dockerfile
    container_name: dzinza-auth-service
    ports:
      - "${AUTH_SERVICE_PORT:-3002}:8000" # Assuming Python service runs on 8000 internally
    volumes:
      - ./auth-service:/home/app/web # Mount code for development
      - shared_config:/etc/shared-config
    environment:
      - PYTHON_APP_MODULE=app.main:app # Example: for FastAPI
      - PORT=8000
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-dzinza_db} # Or specific auth DB if different
      - DB_USER=${DB_USER:-dzinza_user}
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
      - JWT_SECRET_FILE=/run/secrets/jwt_secret
      - JWT_REFRESH_SECRET_FILE=/run/secrets/jwt_refresh_secret
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS_FILE=/run/secrets/smtp_pass
      - GOOGLE_CLIENT_ID_FILE=/run/secrets/google_client_id
      - GOOGLE_CLIENT_SECRET_FILE=/run/secrets/google_client_secret
      - OTEL_SERVICE_NAME=auth-service
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      # Add other necessary env vars
    secrets:
      - db_password
      - redis_password
      - jwt_secret
      - jwt_refresh_secret
      - smtp_pass
      - google_client_id
      - google_client_secret
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend_service: # API Gateway
    build:
      context: ./backend-service
      dockerfile: Dockerfile # Service-specific Dockerfile
    container_name: dzinza-backend-service
    ports:
      - "${GATEWAY_PORT:-3001}:8000" # Gateway port mapping
    volumes:
      - ./backend-service:/home/app/web # Mount code for development
      - shared_config:/etc/shared-config
    environment:
      - DEBUG=${DEBUG:-false}
      # Downstream service URLs (these are picked up by config.py to build the SERVICE_URLS_BY_PREFIX map)
      - AUTH_SERVICE_URL=http://auth_service:8000
      - GENEALOGY_SERVICE_URL=http://genealogy_service:8000
      - SEARCH_SERVICE_URL=http://search_service:8000
      - STORAGE_SERVICE_URL=http://storage_service:8000
      # Add these for the proxy to work correctly inside Docker:
      - AUTH_SERVICE_BASE_URL=http://auth_service:8000
      - GENEALOGY_SERVICE_BASE_URL=http://genealogy_service:8000
      - SEARCH_SERVICE_BASE_URL=http://search_service:8000
      - STORAGE_SERVICE_BASE_URL=http://storage_service:8000
      # JWT settings if gateway validates tokens
      - JWT_SECRET_FILE=/run/secrets/jwt_secret
      - JWT_ALGORITHM=HS256 # Ensure this matches auth-service
      - JWT_AUDIENCE=dzinza-app # Ensure this matches auth-service
      - OTEL_SERVICE_NAME=api-gateway
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - SHARED_CONFIG_PATH=/etc/shared-config/backend.yaml
      - API_V1_STR=/api/v1 # Prefix for gateway's own endpoints (like health)
    secrets:
      - jwt_secret # If gateway validates tokens
      # Add other secrets if gateway directly needs them (e.g., for specific API key auth to downstream)
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on: # Depends on all downstream services it proxies to
      - auth_service
      - genealogy_service
      - genealogy_service_worker # Though not directly called, good to have worker up
      - search_service
      - storage_service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/gateway/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  genealogy_service:
    build:
      context: ./genealogy-service # Path to the Python service code
      dockerfile: Dockerfile # Service-specific Dockerfile (uses base image)
    container_name: dzinza-genealogy-service
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
    ports:
      - "${GENEALOGY_SERVICE_PORT:-3004}:8000" # Expose port, maps to 8000 in container
    volumes:
      - ./genealogy-service:/home/app/web # Mount code for development
      - shared_config:/etc/shared-config # Mount shared configuration volume
    environment:
      - DEBUG=${DEBUG:-false}
      - DB_USER=${DB_USER:-dzinza_user}
      # MongoDB settings - constructed to match what Pydantic settings in config.py expects
      # Assumes MONGO_INITDB_ROOT_USERNAME and MONGO_INITDB_ROOT_PASSWORD_FILE are used for auth.
      # The MONGO_INITDB_ROOT_USERNAME is set to 'dzinza_user' by default in mongodb service.
      - MONGODB_URL=mongodb://${DB_USER:-dzinza_user}:${MONGO_PASSWORD:-mongo_secure_password_456}@mongodb:27017/${MONGODB_GENEALOGY_DB:-dzinza_genealogy}?authSource=admin
      - MONGODB_DATABASE_NAME=${MONGODB_GENEALOGY_DB:-dzinza_genealogy}
      - MONGODB_PASSWORD_FILE=/run/secrets/mongo_password # Path to the secret file for the app to read

      # Celery settings - constructed for Redis broker/backend
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD:-redis_secure_password_789}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD:-redis_secure_password_789}@redis:6379/1
      # Note: The application should read the Redis password from /run/secrets/redis_password and construct the URLs.
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password # App reads this file
      - REDIS_HOST=redis # For Celery config in app

      - OTEL_SERVICE_NAME=genealogy-service
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT} # Example for tracing
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # Add other necessary environment variables, e.g., for shared config path if used by app
      - SHARED_CONFIG_PATH=/etc/shared-config/genealogy.yaml
    secrets:
      - mongo_password # Grant access to MongoDB password secret
      - redis_password # Grant access to Redis password secret
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  genealogy_service_worker: # New service for Celery worker
    build:
      context: ./genealogy-service # Same build context as the API service
      dockerfile: Dockerfile
    container_name: dzinza-genealogy-worker
    command: [
        "celery",
        "-A",
        "celery_worker.celery_app",
        "worker",
        "-l",
        "info",
        "-P",
        "eventlet",
      ] # Updated command to use eventlet pool
    volumes:
      - ./genealogy-service:/home/app/web # Mount code for development
      - shared_config:/etc/shared-config
    environment:
      - DEBUG=${DEBUG:-false}
      - MONGODB_URL=mongodb://${DB_USER:-dzinza_user}:${MONGO_PASSWORD:-mongo_secure_password_456}@mongodb:27017/${MONGODB_GENEALOGY_DB:-dzinza_genealogy}?authSource=admin
      - MONGODB_DATABASE_NAME=${MONGODB_GENEALOGY_DB:-dzinza_genealogy}
      - MONGODB_PASSWORD_FILE=/run/secrets/mongo_password
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
      - REDIS_HOST=redis
      - OTEL_SERVICE_NAME=genealogy-worker # Different service name for tracing
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - SHARED_CONFIG_PATH=/etc/shared-config/genealogy.yaml
      # Note: The application should read the Redis password from /run/secrets/redis_password for Celery URLs.
    secrets:
      - mongo_password
      - redis_password
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on:
      - mongodb
      - redis
      - genealogy_service # Optional: ensure API is up, though worker is independent

  search_service:
    build:
      context: ./search-service
      dockerfile: Dockerfile # Service-specific Dockerfile
    container_name: dzinza-search-service
    ports:
      - "${SEARCH_SERVICE_PORT:-3003}:8000"
    volumes:
      - ./search-service:/home/app/web # Mount code for development
      - shared_config:/etc/shared-config # Mount shared configuration volume
    environment:
      - DEBUG=${DEBUG:-false}
      - PYTHON_ENV=${PYTHON_ENV:-development}
      - PORT=8000

      # Elasticsearch settings (app's config.py will pick the appropriate ones)
      - ELASTICSEARCH_URL=http://elasticsearch:9200 # Primary way to connect
      # - ELASTICSEARCH_CLOUD_ID= # If using Elastic Cloud
      # - ELASTICSEARCH_API_KEY_ID_FILE=/run/secrets/es_api_key_id # If using API key auth
      # - ELASTICSEARCH_API_KEY_FILE=/run/secrets/es_api_key
      # - ELASTICSEARCH_USERNAME_FILE=/run/secrets/es_username # If using basic auth
      # Note: elasticsearch_password secret is available, ES service itself has xpack.security.enabled=false for now.
      # If ES security were enabled, the app's config.py would use ELASTICSEARCH_PASSWORD_FILE.
      - ELASTICSEARCH_PASSWORD_FILE=/run/secrets/elasticsearch_password

      # Index configuration
      - ELASTICSEARCH_INDEX_PERSONS=${ELASTICSEARCH_INDEX_PERSONS:-dzinza_persons}
      - ELASTICSEARCH_INDEX_FAMILY_TREES=${ELASTICSEARCH_INDEX_FAMILY_TREES:-dzinza_family_trees}
      - ELASTICSEARCH_INDEX_EVENTS=${ELASTICSEARCH_INDEX_EVENTS:-dzinza_events}

      # MongoDB for Analytics (if enabled in app config)
      - MONGODB_ANALYTICS_ENABLED=${MONGODB_ANALYTICS_ENABLED:-false}
      - MONGODB_URL_ANALYTICS=mongodb://${DB_USER:-dzinza_user}@mongodb:27017/${MONGODB_SEARCH_DB:-dzinza_search_analytics}?authSource=admin
      - MONGODB_PASSWORD_FILE_ANALYTICS=/run/secrets/mongo_password

      # JWT settings for token validation
      - JWT_SECRET_FILE=/run/secrets/jwt_secret # For token validation if endpoints are protected
      - JWT_ALGORITHM=HS256
      - JWT_AUDIENCE=dzinza-app

      # CORS settings (override default in production)
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:8080,http://dzinza.local}

      # Request timeout and retry settings
      - ELASTICSEARCH_REQUEST_TIMEOUT=${ELASTICSEARCH_REQUEST_TIMEOUT:-30}
      - ELASTICSEARCH_MAX_RETRIES=${ELASTICSEARCH_MAX_RETRIES:-3}
      - ELASTICSEARCH_RETRY_ON_TIMEOUT=${ELASTICSEARCH_RETRY_ON_TIMEOUT:-true}

      # Observability
      - OTEL_SERVICE_NAME=search-service
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      - ENABLE_TRACING=${ENABLE_TRACING:-false}
      - ENABLE_METRICS=${ENABLE_METRICS:-false}

      # Python-specific settings
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - SHARED_CONFIG_PATH=/etc/shared-config/search.yaml
    mem_limit: 512m
    secrets:
      - elasticsearch_password # For ES connection if auth is enabled on ES
      - mongo_password # For analytics DB
      - jwt_secret # For token validation
      # - es_api_key_id        # Example if using ES API key auth
      # - es_api_key
      # - es_username
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
      mongodb: # If analytics enabled and uses MongoDB
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 30s

  storage_service:
    build:
      context: ./storage-service
      dockerfile: Dockerfile # Service-specific Dockerfile
    container_name: dzinza-storage-service
    ports:
      - "${STORAGE_SERVICE_PORT:-3005}:8000"
    volumes:
      - ./storage-service:/home/app/web
      - shared_config:/etc/shared-config
    environment:
      - DEBUG=${DEBUG:-false}
      # MONGODB_URI will be assembled by app from MONGO_HOST, MONGO_DB_NAME, MONGO_USER, MONGO_PASSWORD_FILE
      - MONGO_HOST=mongodb
      - MONGO_DB_NAME=${MONGODB_STORAGE_DB:-dzinza_storage}
      - MONGO_USER=${DB_USER:-dzinza_user} # Using the same user as other DBs for simplicity
      - MONGO_PASSWORD_FILE=/run/secrets/mongo_password

      - AWS_REGION=${AWS_REGION:-garage} # Add AWS_REGION to environment
      - S3_ENDPOINT_URL=http://garage1:39000
      - AWS_ACCESS_KEY_ID_FILE=/run/secrets/aws_access_key_id
      - AWS_SECRET_ACCESS_KEY_FILE=/run/secrets/aws_secret_access_key
      - S3_BUCKET_NAME=dzinza-storage-bucket
      - S3_FORCE_PATH_STYLE=true
      - S3_CREATE_BUCKET_IF_NOT_EXISTS=true
      # Note: Ensure the bucket 'dzinza-storage-bucket' exists in Garage or is created on startup by the application.

      - JWT_SECRET_FILE=/run/secrets/jwt_secret # For token validation
      - JWT_ALGORITHM=HS256 # Must match auth-service
      - JWT_AUDIENCE=dzinza-app # Must match auth-service

      - OTEL_SERVICE_NAME=storage-service
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - SHARED_CONFIG_PATH=/etc/shared-config/storage.yaml
    secrets:
      - mongo_password # For metadata DB
      - aws_access_key_id
      - aws_secret_access_key
      - jwt_secret # For token validation
    networks:
      - dzinza-network
    restart: unless-stopped
    depends_on:
      - mongodb
      - garage1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Garage S3-compatible Service
  garage1:
    image: dxflrs/garage:v2.0.0
    container_name: dzinza-garage1
    hostname: garage1
    ports:
      - "39000:39000" # S3 API
      - "39011:39011" # RPC
      - "39021:39021" # Web admin
    volumes:
      - ./garage/garage1.toml:/etc/garage.toml
      - garage1_data:/var/lib/garage/data1
      - garage1_meta:/var/lib/garage/meta1
    networks:
      - dzinza-network
    restart: unless-stopped

  garage2:
    image: dxflrs/garage:v2.0.0
    container_name: dzinza-garage2
    hostname: garage2
    ports:
      - "39002:39002" # S3 API
      - "39012:39012" # RPC
      - "39022:39022" # Web admin
    volumes:
      - ./garage/garage2.toml:/etc/garage.toml
      - garage2_data:/var/lib/garage/data2
      - garage2_meta:/var/lib/garage/meta2
    networks:
      - dzinza-network
    restart: unless-stopped

  garage3:
    image: dxflrs/garage:v2.0.0
    container_name: dzinza-garage3
    hostname: garage3
    ports:
      - "39003:39003" # S3 API
      - "39013:39013" # RPC
      - "39023:39023" # Web admin
    volumes:
      - ./garage/garage3.toml:/etc/garage.toml
      - garage3_data:/var/lib/garage/data3
      - garage3_meta:/var/lib/garage/meta3
    networks:
      - dzinza-network
    restart: unless-stopped

volumes:
  postgres_data:
  mongodb_data:
  redis_data:
  elasticsearch_data:
  prometheus_data:
  grafana_data:
  shared_config: # Define the shared_config volume
  minio_data: # Data volume for MinIO
  garage_data: # Data volume for Garage
  garage_metadata: # Metadata volume for Garage
  garage1_data:
  garage1_meta:
  garage2_data:
  garage2_meta:
  garage3_data:
  garage3_meta:

networks:
  dzinza-network:
    driver: bridge # Default network driver, can be customized if needed
